{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drivendata waterpump.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mspoorendonk/drivendata/blob/marc/drivendata_waterpump.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC9Hngyu5E6R"
      },
      "source": [
        "# Analysis of condition of water points in Tanzania\n",
        "\n",
        "Problem statement:\n",
        "predict the operating condition of a waterpoint for each record in the dataset: functioning, functioning but needs repair, not functioning\n",
        "\n",
        "\n",
        "Approach\n",
        "1. Download datasets\n",
        "1. Explore data and understand which features are relevant for the prediction. \n",
        "1. Clean data [Bart]\n",
        "1. Engineer some derived features\n",
        "1. decide on a method for predicting (trees or neuralnets or knn or ...)\n",
        "1. perform a train / test / validate split on the data\n",
        "1. Train model on training values and labels\n",
        "1. Predict training labels that correspond to training values\n",
        "1. Report the accuracy\n",
        "1. Tune hyperparameters with gridsearch\n",
        "1. Predict the test labels\n",
        "1. Submit CSV [Marc]\n",
        "\n",
        "\n",
        "TODO:\n",
        "here: check xgboost, pandas, bokeh (interactief)\n",
        "somewhere else: how to deploy a model in production. What software and frameworks etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwqftAGR-k2J"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuCGSSOKu8-h"
      },
      "source": [
        "# installations\n",
        "\n",
        "!pip install gmaps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJlE0N65YUFd"
      },
      "source": [
        "# imports\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import gmaps\n",
        "import IPython\n",
        "from sklearn import tree # to create a decision tree\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics # to compute accuracy\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import preprocessing # for normalizing data for knn\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pydotplus # To create our Decision Tree Graph\n",
        "from IPython.display import Image  # To Display a image of our graph\n",
        "\n",
        "from ipywidgets.embed import embed_minimal_html\n",
        "\n",
        "# Seaborn visualization library\n",
        "import seaborn as sns # for pairplots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOSkSXlq-gzD"
      },
      "source": [
        "# Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGa2jMrp23Sm"
      },
      "source": [
        "# download datasets from driven-data.org. Urls copied from data download section on website.\n",
        "\n",
        "# testvalues\n",
        "!wget \"https://drivendata-prod.s3.amazonaws.com/data/7/public/702ddfc5-68cd-4d1d-a0de-f5f566f76d91.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200925%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200925T082148Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=0ac3b542d2e76bd23a37c1647c08e6f063c11f8bec8e912bc55049624bb8e35a\" -O test_values.csv\n",
        "# training labels\n",
        "!wget \"https://drivendata-prod.s3.amazonaws.com/data/7/public/0bf8bc6e-30d0-4c50-956a-603fc693d966.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200925%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200925T082148Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7993cf70a3479b055a07ecb066fab1f84c1e759796214a67cb9164eb075374be\" -O training_labels.csv\n",
        "# training values\n",
        "!wget \"https://drivendata-prod.s3.amazonaws.com/data/7/public/4910797b-ee55-40a7-8668-10efd5c1b960.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCY3EFSLNZR%2F20200925%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200925T082148Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=b6a338290d5d045bed729fab9efcec5bd6613d7fd7545317c742ee60bbfb3d25\" -O training_values.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5JdImi9qyql"
      },
      "source": [
        "# Boundary coordinates of Tanzania\n",
        "# Source: https://en.wikipedia.org/wiki/List_of_countries_by_northernmost_point (and similar)\n",
        "tanzania_lat = [-11.750-0.1, -0.983+0.1]\n",
        "tanzania_lon = [29.167-0.1, 40.250+0.1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlOL83NOOp9n"
      },
      "source": [
        "training_values = pd.read_csv('training_values.csv', parse_dates=['date_recorded'])\n",
        "training_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dJiyxY0knjO"
      },
      "source": [
        "training_values.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlLffN6gjbFB"
      },
      "source": [
        "# training_values.sort_values('wpt_name').head()\n",
        "# check if ['id'] is unique\n",
        "print('Number of duplicate ids: ', training_values.duplicated(subset=['id']).sum())\n",
        "\n",
        "# check if latitude, longitude is in Tanzania\n",
        "lon_in_range = (tanzania_lon[0] <= training_values['longitude']) & \\\n",
        "               (training_values['longitude'] <= tanzania_lon[1])\n",
        "lat_in_range = (tanzania_lat[0] <= training_values['latitude']) & \\\n",
        "               (training_values['latitude'] <= tanzania_lat[1])\n",
        "pos_in_range = lon_in_range & lat_in_range\n",
        "print('Number of invalid coordinates: ', (~pos_in_range).sum())\n",
        "\n",
        "duplicate_location = training_values.duplicated(subset=['longitude', 'latitude'])\n",
        "training_values[duplicate_location].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXko4e2zOyim"
      },
      "source": [
        "training_values.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENzTAPCrQeYJ"
      },
      "source": [
        "training_labels = pd.read_csv('training_labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u637XYufRh8f"
      },
      "source": [
        "training_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyL52BBIFcsH"
      },
      "source": [
        "training_all = pd.concat([training_values, training_labels], axis=1) # get them side by side\n",
        "\n",
        "\n",
        "# Create the default pairplot\n",
        "sns.pairplot(training_all[['date_recorded', 'funder',\t'gps_height',\t'installer', 'status_group']], hue = 'status_group')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPHHIaJI-tVR"
      },
      "source": [
        "# Engineer features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XscRcgEZRYuQ"
      },
      "source": [
        "# engineer some features\n",
        "\n",
        "# maybe days since reporting a functional pump?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI-9_Bsg-zaK"
      },
      "source": [
        "# Explore data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLzANEKyRuS9"
      },
      "source": [
        "# plot n pumps on a map. Everything above 200 gets slow\n",
        "\n",
        "n = 200\n",
        "\n",
        "gmaps.configure(api_key=\"AIzaSyCDAaxun4CXAyEmLzzJbYkqXii-sbVhVNc\")  # This is my personal API key, please don't abuse.\n",
        "\n",
        "\n",
        "\n",
        "colors = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "sampled_pumps = training_values.sample(n)\n",
        "\n",
        "for i in range(len(sampled_pumps)):\n",
        "  id = sampled_pumps.iloc[i]['id']\n",
        "  #print(id)\n",
        "  state = training_labels[training_labels['id']==id]['status_group'].iloc[0]\n",
        "  if state=='functional':\n",
        "    colors.append('green')\n",
        "  elif state=='non functional':\n",
        "    colors.append('red') \n",
        "  else:\n",
        "    colors.append('yellow') # needs repair\n",
        "\n",
        "  labels.append('source %s' % sampled_pumps[sampled_pumps['id']==id].iloc[0]['source'])\n",
        "\n",
        "\n",
        "pump_locations = sampled_pumps[['latitude' , 'longitude']]\n",
        "info_box_template = \"\"\"\n",
        "<dl>\n",
        "\n",
        "<td>Name</td><dd>{scheme_name}</dd>\n",
        "</dl>\n",
        "\"\"\"\n",
        "\n",
        "pump_info = training_values['scheme_name'][:2]\n",
        "\n",
        "#marker_layer = gmaps.marker_layer(pump_locations, hover_text=pump_info, info_box_content=pump_info)\n",
        "marker_layer = gmaps.symbol_layer(pump_locations, fill_color=colors, stroke_color=colors, scale=3, hover_text=labels)\n",
        "figure_layout = {\n",
        "    'width': '1400px',\n",
        "    'height': '1200px',\n",
        "    'border': '1px solid black',\n",
        "    'padding': '1px'\n",
        "}\n",
        "\n",
        "fig = gmaps.figure(layout=figure_layout)\n",
        "fig.add_layer(marker_layer)\n",
        "#fig\n",
        "embed_minimal_html('export.html', views=[fig])\n",
        "IPython.display.HTML(filename='export.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oP1BmwhaoD9"
      },
      "source": [
        "training_values[['longitude', 'latitude']].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFoRLkhd-5Ca"
      },
      "source": [
        "# Prepare for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd8zedFQX7JF"
      },
      "source": [
        "\n",
        "\n",
        "n = 10000\n",
        "n = len(training_values)\n",
        "# select the describing variables\n",
        "X = pd.get_dummies(training_values[['id', 'date_recorded', 'amount_tsh',\t'gps_height',\t'longitude',\t'latitude',\t'num_private',\t'region_code',\t'district_code',\t'population',\t'construction_year', 'source', 'quality_group', 'quantity_group', 'extraction_type_group'\t]][:n])\n",
        "X['date_recorded']=pd.to_numeric(X['date_recorded']) # otherwise dates get ignored in the correlation and the tree\n",
        "\n",
        "Y = pd.get_dummies(training_labels[['status_group']][:n])\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X_train_normalized = scaler.transform(X_train)\n",
        "X_test_normalized  = scaler.transform(X_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPhexPmsgZ0-"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu8gomyui65T"
      },
      "source": [
        "Y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqlNFS1OUrAN"
      },
      "source": [
        "# figure out which variables correlate with Y\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "sn.set(rc={'figure.facecolor':'#a0a0a0'})\n",
        "\n",
        "XY=pd.concat([X, Y], axis=1) # get them side by side\n",
        "\n",
        "corrMatrix = XY.corr()\n",
        "plt.figure(figsize=(40,15))\n",
        "# for tips on formatting the heatmap:\n",
        "# https://heartbeat.fritz.ai/seaborn-heatmaps-13-ways-to-customize-correlation-matrix-visualizations-f1c49c816f07\n",
        "sn.heatmap(corrMatrix, annot=True,  fmt='.2f', vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4kSUXIHqJwe"
      },
      "source": [
        "X.head(), Y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnfLpQ-IRJuI"
      },
      "source": [
        "#Forecast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyNH4rTsRlO0"
      },
      "source": [
        "##Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZDyxJP1lXAp",
        "outputId": "6f66801a-7524-4531-f63e-2c6b420e5d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(\"Train on %d samples. Test on %d samples.\" % (len(X_train), len(X_test)))\n",
        "\n",
        "for d in [1, 5, 10, 15, 20, 25, 5]: # end with 5 so it can be plotted in next cell\n",
        "  model = tree.DecisionTreeClassifier(criterion='gini',max_depth=d)\n",
        "  model = model.fit(X_train, Y_train)\n",
        "\n",
        "  #Predict the response for test dataset\n",
        "  y_pred = model.predict(X_test)\n",
        "  correct = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    y_vals = Y_test.iloc[i].values\n",
        "    y_pred_vals = y_pred[i]\n",
        "    #print(y_vals, y_pred_vals)\n",
        "    if (y_vals == y_pred_vals).all():\n",
        "      #print(\"correct\")\n",
        "      correct += 1\n",
        "    #else:\n",
        "      #print('incorrect')\n",
        "    #if correct>10: break  \n",
        "\n",
        "  print(\"Max depth: %d   Accuracy on test set: %.2f   #correct: %d\" % (d, correct/len(y_pred), correct))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 47520 samples. Test on 11880 samples.\n",
            "Max depth: 1   Accuracy on test set: 0.64   #correct: 7632\n",
            "Max depth: 5   Accuracy on test set: 0.70   #correct: 8335\n",
            "Max depth: 10   Accuracy on test set: 0.70   #correct: 8336\n",
            "Max depth: 15   Accuracy on test set: 0.73   #correct: 8625\n",
            "Max depth: 20   Accuracy on test set: 0.76   #correct: 9008\n",
            "Max depth: 25   Accuracy on test set: 0.75   #correct: 8915\n",
            "Max depth: 5   Accuracy on test set: 0.70   #correct: 8335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQp0frzjlYo_",
        "outputId": "440f0f9f-6331-4020-e3a9-48aae931dbae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Export/Print a decision tree in DOT format. Only do this when max_depth is small (<=6) otherwise it gets too slow.\n",
        "#print(tree.export_graphviz(clf, None))\n",
        "\n",
        "if d < 6:\n",
        "  print('creating image')\n",
        "  #Create Dot Data\n",
        "  dot_data = tree.export_graphviz(model, out_file=None, feature_names=list(X_train.columns.values), \n",
        "                                  class_names=['func', 'repair', 'nonfunc'], rounded=True, filled=True) #Gini decides which attribute/feature should be placed at the root node, which features will act as internal nodes or leaf nodes\n",
        "  #print(dot_data)\n",
        "  #Create Graph from DOT data\n",
        "  graph = pydotplus.graph_from_dot_data(dot_data)\n",
        "\n",
        "  # Show graph\n",
        "  Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TitZ_1pRbHIu"
      },
      "source": [
        "##Random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwKWxHMmasjX",
        "outputId": "ef28e9e0-a683-4c07-f1d1-8ca9b80b27af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Train on %d samples. Test on %d samples.\" % (len(X_train), len(X_test)))\n",
        "\n",
        "\n",
        "model = RandomForestClassifier(n_jobs=None,random_state=27,verbose=0, max_depth=20, criterion='gini')\n",
        "model = model.fit(X_train, Y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_test)\n",
        "correct = 0\n",
        "for i in range(len(y_pred)):\n",
        "  y_vals = Y_test.iloc[i].values\n",
        "  y_pred_vals = y_pred[i]\n",
        "  #print(y_vals, y_pred_vals)\n",
        "  if (y_vals == y_pred_vals).all():\n",
        "    #print(\"correct\")\n",
        "    correct += 1\n",
        "  #else:\n",
        "    #print('incorrect')\n",
        "  #if correct>10: break  \n",
        "\n",
        "print(\"Max depth: %d   Accuracy on test set: %.2f   #correct: %d\" % (d, correct/len(y_pred), correct))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 47520 samples. Test on 11880 samples.\n",
            "Max depth: 5   Accuracy on test set: 0.78   #correct: 9210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0aE1t8RRTO"
      },
      "source": [
        "##KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBkoB37GCayu",
        "outputId": "5bbf40db-0e48-4970-a945-1ccaa0b1def7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "print(\"Train on %d samples. Test on %d samples.\" % (len(X_train), len(X_test)))\n",
        "\n",
        "\n",
        "\n",
        "for d in range(1,20):\n",
        "  model = KNeighborsClassifier(n_neighbors=d)\n",
        "  model = model.fit(X_train_normalized, Y_train)\n",
        "\n",
        "  #Predict the response for test dataset\n",
        "  y_pred = model.predict(X_test_normalized)\n",
        "  correct = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    y_vals = Y_test.iloc[i].values\n",
        "    y_pred_vals = y_pred[i]\n",
        "    #print(y_vals, y_pred_vals)\n",
        "    if (y_vals == y_pred_vals).all():\n",
        "      #print(\"correct\")\n",
        "      correct += 1\n",
        "    #else:\n",
        "      #print('incorrect')\n",
        "    #if correct>10: break  \n",
        "\n",
        "  print(\"n_neighbors: %d   Accuracy on test set: %.2f   #correct: %d\" % (d, correct/len(y_pred), correct))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples. Test on 2000 samples.\n",
            "n_neighbors: 1   Accuracy on test set: 0.65   #correct: 1299\n",
            "n_neighbors: 2   Accuracy on test set: 0.49   #correct: 972\n",
            "n_neighbors: 3   Accuracy on test set: 0.66   #correct: 1310\n",
            "n_neighbors: 4   Accuracy on test set: 0.57   #correct: 1135\n",
            "n_neighbors: 5   Accuracy on test set: 0.66   #correct: 1318\n",
            "n_neighbors: 6   Accuracy on test set: 0.59   #correct: 1180\n",
            "n_neighbors: 7   Accuracy on test set: 0.66   #correct: 1314\n",
            "n_neighbors: 8   Accuracy on test set: 0.61   #correct: 1221\n",
            "n_neighbors: 9   Accuracy on test set: 0.67   #correct: 1330\n",
            "n_neighbors: 10   Accuracy on test set: 0.61   #correct: 1219\n",
            "n_neighbors: 11   Accuracy on test set: 0.66   #correct: 1313\n",
            "n_neighbors: 12   Accuracy on test set: 0.62   #correct: 1243\n",
            "n_neighbors: 13   Accuracy on test set: 0.66   #correct: 1318\n",
            "n_neighbors: 14   Accuracy on test set: 0.63   #correct: 1257\n",
            "n_neighbors: 15   Accuracy on test set: 0.66   #correct: 1317\n",
            "n_neighbors: 16   Accuracy on test set: 0.63   #correct: 1261\n",
            "n_neighbors: 17   Accuracy on test set: 0.66   #correct: 1314\n",
            "n_neighbors: 18   Accuracy on test set: 0.63   #correct: 1261\n",
            "n_neighbors: 19   Accuracy on test set: 0.66   #correct: 1320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-cFwS5CHzMB",
        "outputId": "b5881c65-7033-4b60-ff0b-099d8e0ea5f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "pd.DataFrame( Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status_group_functional</th>\n",
              "      <th>status_group_functional needs repair</th>\n",
              "      <th>status_group_non functional</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2694</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5140</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2568</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3671</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7427</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2895</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7813</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5192</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      status_group_functional  ...  status_group_non functional\n",
              "2694                        0  ...                            1\n",
              "5140                        0  ...                            1\n",
              "2568                        1  ...                            0\n",
              "3671                        1  ...                            0\n",
              "7427                        1  ...                            0\n",
              "...                       ...  ...                          ...\n",
              "2895                        1  ...                            0\n",
              "7813                        1  ...                            0\n",
              "905                         0  ...                            1\n",
              "5192                        1  ...                            0\n",
              "235                         0  ...                            1\n",
              "\n",
              "[8000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gM_orokRXhO"
      },
      "source": [
        "##Neuralnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPk1W5P-E4iv",
        "outputId": "e88c8b7e-da78-4f3e-d858-ed3796574577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Train on %d samples. Test on %d samples.\" % (len(X_train), len(X_test)))\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential()\n",
        "#model.add(layers.Dense(2, activation=\"relu\"))\n",
        "model.add(layers.Dense(10,  activation=\"relu\", input_shape = (45,)))\n",
        "model.add(layers.Dense(5,  activation=\"relu\"))\n",
        "model.add(layers.Dense(3,   activation='sigmoid'))\n",
        "model.compile('adam', \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x=X_train_normalized, y=Y_train, epochs=35)\n",
        "model.summary()\n",
        "\n",
        "y_pred = model.predict(X_test_normalized)\n",
        "print(len(y_pred))\n",
        "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
        "\n",
        "correct = 0\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  y_vals = Y_test.iloc[i].values\n",
        "  y_pred_vals = y_pred[i]\n",
        "  #print('x', X_test[i])\n",
        "  #print(y_vals, y_pred_vals)\n",
        "  if (y_vals == y_pred_vals).all():\n",
        "    #print(\"correct\")\n",
        "    correct += 1\n",
        "  #else:\n",
        "    #print('incorrect')\n",
        "  #if i>20: break  \n",
        "\n",
        "print(\"Accuracy on test set: %.2f   #correct: %d\" % (correct/len(y_pred), correct))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples. Test on 2000 samples.\n",
            "Epoch 1/35\n",
            "250/250 [==============================] - 0s 906us/step - loss: 0.6420 - accuracy: 0.4092\n",
            "Epoch 2/35\n",
            "250/250 [==============================] - 0s 917us/step - loss: 0.5488 - accuracy: 0.5347\n",
            "Epoch 3/35\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.4974 - accuracy: 0.6783\n",
            "Epoch 4/35\n",
            "250/250 [==============================] - 0s 925us/step - loss: 0.4487 - accuracy: 0.6982\n",
            "Epoch 5/35\n",
            "250/250 [==============================] - 0s 937us/step - loss: 0.4361 - accuracy: 0.7039\n",
            "Epoch 6/35\n",
            "250/250 [==============================] - 0s 940us/step - loss: 0.4315 - accuracy: 0.7041\n",
            "Epoch 7/35\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7050\n",
            "Epoch 8/35\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.4274 - accuracy: 0.7042\n",
            "Epoch 9/35\n",
            "250/250 [==============================] - 0s 933us/step - loss: 0.4261 - accuracy: 0.7056\n",
            "Epoch 10/35\n",
            "250/250 [==============================] - 0s 972us/step - loss: 0.4252 - accuracy: 0.7074\n",
            "Epoch 11/35\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.4242 - accuracy: 0.7057\n",
            "Epoch 12/35\n",
            "250/250 [==============================] - 0s 948us/step - loss: 0.4234 - accuracy: 0.7097\n",
            "Epoch 13/35\n",
            "250/250 [==============================] - 0s 929us/step - loss: 0.4225 - accuracy: 0.7081\n",
            "Epoch 14/35\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7088\n",
            "Epoch 15/35\n",
            "250/250 [==============================] - 0s 918us/step - loss: 0.4214 - accuracy: 0.7099\n",
            "Epoch 16/35\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.4210 - accuracy: 0.7105\n",
            "Epoch 17/35\n",
            "250/250 [==============================] - 0s 947us/step - loss: 0.4202 - accuracy: 0.7110\n",
            "Epoch 18/35\n",
            "250/250 [==============================] - 0s 969us/step - loss: 0.4197 - accuracy: 0.7111\n",
            "Epoch 19/35\n",
            "250/250 [==============================] - 0s 943us/step - loss: 0.4194 - accuracy: 0.7120\n",
            "Epoch 20/35\n",
            "250/250 [==============================] - 0s 920us/step - loss: 0.4191 - accuracy: 0.7119\n",
            "Epoch 21/35\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.7115\n",
            "Epoch 22/35\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.7113\n",
            "Epoch 23/35\n",
            "250/250 [==============================] - 0s 958us/step - loss: 0.4173 - accuracy: 0.7135\n",
            "Epoch 24/35\n",
            "250/250 [==============================] - 0s 913us/step - loss: 0.4175 - accuracy: 0.7117\n",
            "Epoch 25/35\n",
            "250/250 [==============================] - 0s 950us/step - loss: 0.4171 - accuracy: 0.7125\n",
            "Epoch 26/35\n",
            "250/250 [==============================] - 0s 996us/step - loss: 0.4162 - accuracy: 0.7120\n",
            "Epoch 27/35\n",
            "250/250 [==============================] - 0s 960us/step - loss: 0.4162 - accuracy: 0.7124\n",
            "Epoch 28/35\n",
            "250/250 [==============================] - 0s 927us/step - loss: 0.4158 - accuracy: 0.7106\n",
            "Epoch 29/35\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.7121\n",
            "Epoch 30/35\n",
            "250/250 [==============================] - 0s 965us/step - loss: 0.4155 - accuracy: 0.7136\n",
            "Epoch 31/35\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.4149 - accuracy: 0.7136\n",
            "Epoch 32/35\n",
            "250/250 [==============================] - 0s 962us/step - loss: 0.4149 - accuracy: 0.7122\n",
            "Epoch 33/35\n",
            "250/250 [==============================] - 0s 955us/step - loss: 0.4141 - accuracy: 0.7149\n",
            "Epoch 34/35\n",
            "250/250 [==============================] - 0s 939us/step - loss: 0.4142 - accuracy: 0.7139\n",
            "Epoch 35/35\n",
            "250/250 [==============================] - 0s 945us/step - loss: 0.4139 - accuracy: 0.7149\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                460       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 18        \n",
            "=================================================================\n",
            "Total params: 533\n",
            "Trainable params: 533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2000\n",
            "Accuracy on test set: 0.66   #correct: 1315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSrcI0Gae9cE"
      },
      "source": [
        "##XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwCo_6lJCtV1",
        "outputId": "a2f1f472-d8e6-4dc3-dc4a-576b21a31da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# inspired by: https://medium.com/@gabrielziegler3/multiclass-multilabel-classification-with-xgboost-66195e4d9f2d\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "model = XGBClassifier(max_depth=5, objective='multi:softprob', n_estimators=1000, \n",
        "                        num_classes=3)\n",
        "model = model.fit(X_train_normalized, Y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_test_normalized)\n",
        "correct = 0\n",
        "for i in range(len(y_pred)):\n",
        "  y_vals = Y_test.iloc[i].values\n",
        "  y_pred_vals = y_pred[i]\n",
        "  #print(y_vals, y_pred_vals)\n",
        "  if (y_vals == y_pred_vals).all():\n",
        "    #print(\"correct\")\n",
        "    correct += 1\n",
        "  #else:\n",
        "    #print('incorrect')\n",
        "  #if correct>10: break  \n",
        "\n",
        "print(\"n_neighbors: %d   Accuracy on test set: %.2f   #correct: %d\" % (d, correct/len(y_pred), correct))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-71a8cf87d3dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m model = XGBClassifier(max_depth=5, objective='multi:softprob', n_estimators=1000, \n\u001b[1;32m     10\u001b[0m                         num_classes=3)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0mxgb_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"eval_metric\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: bad input shape (8000, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK24eHPVfFQw",
        "outputId": "47530076-5919-46c2-a059-9440d2b4c65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# inspiration: https://www.kaggle.com/stuarthallows/using-xgboost-with-scikit-learn\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "\n",
        "#for d in range(1,35):\n",
        "for d in [15]:\n",
        "  model = OneVsRestClassifier(XGBClassifier(n_jobs=-1, max_depth=d, objective=\"multi:softprob\", num_class=3))\n",
        "  model = model.fit(X_train_normalized, Y_train)\n",
        "\n",
        "  #Predict the response for test dataset\n",
        "  y_pred = model.predict(X_test_normalized)\n",
        "  correct = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    y_vals = Y_test.iloc[i].values\n",
        "    y_pred_vals = y_pred[i]\n",
        "    #print(y_vals, y_pred_vals)\n",
        "    if (y_vals == y_pred_vals).all():\n",
        "      #print(\"correct\")\n",
        "      correct += 1\n",
        "    #else:\n",
        "      #print('incorrect')\n",
        "    #if correct>10: break  \n",
        "\n",
        "  print(\"XGBoost: %d   Accuracy on test set: %.2f   #correct: %d\" % (d, correct/len(y_pred), correct))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBoost: 15   Accuracy on test set: 0.70   #correct: 1403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtt6Yw9AZMoc"
      },
      "source": [
        "#print(confusion_matrix(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKXg_c92EjZZ"
      },
      "source": [
        "#Evaluation\n",
        "- randomforest: .72 \n",
        "- tree: .70\n",
        "- xgboost: .70\n",
        "- nn: .65\n",
        "- knn: .48"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6LPzRASj4M5"
      },
      "source": [
        "import requests\n",
        "gcloud_token = !gcloud auth print-access-token\n",
        "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "gcloud_tokeninfo\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCP5KqEo9r5I"
      },
      "source": [
        "!set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHrNq7Z1PuQt"
      },
      "source": [
        "#Submit result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ag_iZe-aE3",
        "outputId": "f03b214b-68e3-489f-9a5d-f78f82e13052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        }
      },
      "source": [
        "print('train model')\n",
        "\n",
        "model = RandomForestClassifier(n_jobs=None,random_state=27,verbose=0, max_depth=20, criterion='gini')\n",
        "model = model.fit(X, Y)\n",
        "\n",
        "print('predict')\n",
        "test_values = pd.read_csv('test_values.csv', parse_dates=['date_recorded'])\n",
        "X_submission = pd.get_dummies(test_values[['id', 'date_recorded', 'amount_tsh',\t'gps_height',\t'longitude',\t'latitude',\t'num_private',\t'region_code',\t'district_code',\t'population',\t'construction_year', 'source', 'quality_group', 'quantity_group', 'extraction_type_group'\t]])\n",
        "X_submission['date_recorded']=pd.to_numeric(X_submission['date_recorded']) # otherwise dates get ignored in the correlation and the tree\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = model.predict(X_submission)\n",
        "\n",
        "print('create submission')\n",
        "# create a dataframe for submission\n",
        "# TODO: For better performance write this without a loop with a zip() or map()\n",
        "submission = pd.DataFrame(columns=['id', 'status_group'])\n",
        "for i in range(len(y_pred)):\n",
        "  if y_pred[i][0]: status='functional'\n",
        "  if y_pred[i][1]: status='functional needs repair'\n",
        "  if y_pred[i][2]: status='non functional'\n",
        "  submission=submission.append({'id': test_values.iloc[i]['id'], 'status_group': status}, ignore_index=True)\n",
        "\n",
        "# save as csv\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train model\n",
            "predict\n",
            "create submission\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50785</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>51630</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17168</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45559</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49871</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14845</th>\n",
              "      <td>39307</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14846</th>\n",
              "      <td>18990</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14847</th>\n",
              "      <td>28749</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14848</th>\n",
              "      <td>33492</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14849</th>\n",
              "      <td>68707</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14850 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id    status_group\n",
              "0      50785      functional\n",
              "1      51630      functional\n",
              "2      17168      functional\n",
              "3      45559  non functional\n",
              "4      49871      functional\n",
              "...      ...             ...\n",
              "14845  39307  non functional\n",
              "14846  18990      functional\n",
              "14847  28749      functional\n",
              "14848  33492      functional\n",
              "14849  68707  non functional\n",
              "\n",
              "[14850 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Qv6DQ-SS5Gi"
      },
      "source": [
        "test_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Vdfr1-xWIJD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
